{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8490842,
     "sourceType": "datasetVersion",
     "datasetId": 5065701
    },
    {
     "sourceId": 8498424,
     "sourceType": "datasetVersion",
     "datasetId": 5071288
    },
    {
     "sourceId": 8509469,
     "sourceType": "datasetVersion",
     "datasetId": 5079545
    },
    {
     "sourceId": 8509507,
     "sourceType": "datasetVersion",
     "datasetId": 5079571
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install ultralytics"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-05-26T18:08:18.086772Z",
     "iopub.execute_input": "2024-05-26T18:08:18.087609Z",
     "iopub.status.idle": "2024-05-26T18:08:33.578944Z",
     "shell.execute_reply.started": "2024-05-26T18:08:18.087569Z",
     "shell.execute_reply": "2024-05-26T18:08:33.578016Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:04:52.363754Z",
     "start_time": "2024-05-27T18:04:51.171761Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (8.2.22)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (3.9.0)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (4.9.0.80)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (10.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (2.32.2)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (0.18.0)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (4.66.4)\r\n",
      "Requirement already satisfied: psutil in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (5.9.8)\r\n",
      "Requirement already satisfied: py-cpuinfo in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (2.2.2)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from ultralytics) (0.13.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.52.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\r\n",
      "Requirement already satisfied: filelock in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.12.0)\r\n",
      "Requirement already satisfied: sympy in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.19.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/alialghamdi/miniconda3/envs/deep_learning/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U ipywidgets"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-26T18:08:33.580915Z",
     "iopub.execute_input": "2024-05-26T18:08:33.581218Z",
     "iopub.status.idle": "2024-05-26T18:08:47.124906Z",
     "shell.execute_reply.started": "2024-05-26T18:08:33.581190Z",
     "shell.execute_reply": "2024-05-26T18:08:47.123653Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:04:52.801078Z",
     "start_time": "2024-05-27T18:04:52.365438Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from ultralytics import YOLO",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-26T18:08:47.126286Z",
     "iopub.execute_input": "2024-05-26T18:08:47.126660Z",
     "iopub.status.idle": "2024-05-26T18:08:51.541486Z",
     "shell.execute_reply.started": "2024-05-26T18:08:47.126630Z",
     "shell.execute_reply": "2024-05-26T18:08:51.540486Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T23:53:08.569354Z",
     "start_time": "2024-05-27T23:53:05.500572Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "#### Training the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "results = model.train(\n",
    "    data= '/kaggle/input/80-10-10-dataset/data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    patience=50,\n",
    "    device=0,\n",
    "    batch=64,\n",
    "    optimizer= 'SGD',\n",
    "    momentum=0.95\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T18:04:56.645228Z",
     "start_time": "2024-05-27T18:04:56.645171Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = YOLO(\"best_80_10_10.pt\")  \n",
    "\n",
    "metrics = model.val()  \n",
    "metrics.box.map  \n",
    "metrics.box.map50  \n",
    "metrics.box.map75  \n",
    "metrics.box.maps  "
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### hyperparameter-tuning\n",
    "\n",
    "- in our case SGD as optimizer is better that AdamW\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = YOLO(\"best_s_version.pt\") "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-26T18:13:53.945523Z",
     "iopub.execute_input": "2024-05-26T18:13:53.945933Z",
     "iopub.status.idle": "2024-05-26T18:13:53.995167Z",
     "shell.execute_reply.started": "2024-05-26T18:13:53.945903Z",
     "shell.execute_reply": "2024-05-26T18:13:53.994307Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- lr0 = [0.0005, **0.001**, 0.005]\n",
    "- lrf = [0.01, **0.005**]\n",
    "- batch = [16, **32**, 64]\n",
    "- momentum = [0.85, **0.9**, 0.95]\n",
    "- warmup_momentum = [**0.5**]\n",
    "- warmup_bias_lr = [**0.05**, 0.1, 0.2]\n",
    "- weight_decay = [0.0001, **0.0005**, 0.001]\n",
    "- patience = [**30**, 50]\n",
    "- imgsz = [**640**, 800, 1024]\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data='/kaggle/input/80-10-10-dataset/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    patience=30,  \n",
    "    device=0,\n",
    "    batch=32,  \n",
    "    optimizer='SGD',  \n",
    "    lr0=0.001,  \n",
    "    lrf=0.005,\n",
    "    momentum=0.9,\n",
    "    warmup_momentum=0.5,\n",
    "    warmup_bias_lr=0.05,\n",
    "    weight_decay=0.0005,  \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics.utils.plotting import Annotator\n",
    "import cv2"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:53:37.525213Z",
     "start_time": "2024-05-27T23:53:37.509220Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "model = YOLO(\"best_s_version.pt\") \n",
    "video_path = 'sample_02.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T23:24:09.423656Z",
     "start_time": "2024-05-27T23:24:08.270833Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_s_version.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mYOLO\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbest_s_version.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \n\u001B[0;32m      2\u001B[0m video_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample_02.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m cap \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mVideoCapture(video_path)\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001B[0m, in \u001B[0;36mYOLO.__init__\u001B[1;34m(self, model, task, verbose)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m \u001B[38;5;241m=\u001B[39m new_instance\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# Continue with default YOLO initialization\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\ultralytics\\engine\\model.py:152\u001B[0m, in \u001B[0;36mModel.__init__\u001B[1;34m(self, model, task, verbose)\u001B[0m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new(model, task\u001B[38;5;241m=\u001B[39mtask, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\ultralytics\\engine\\model.py:241\u001B[0m, in \u001B[0;36mModel._load\u001B[1;34m(self, weights, task)\u001B[0m\n\u001B[0;32m    238\u001B[0m weights \u001B[38;5;241m=\u001B[39m checks\u001B[38;5;241m.\u001B[39mcheck_model_file_from_stem(weights)  \u001B[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001B[39;00m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Path(weights)\u001B[38;5;241m.\u001B[39msuffix \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 241\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt \u001B[38;5;241m=\u001B[39m \u001B[43mattempt_load_one_weight\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moverrides \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39margs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset_ckpt_args(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39margs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\ultralytics\\nn\\tasks.py:806\u001B[0m, in \u001B[0;36mattempt_load_one_weight\u001B[1;34m(weight, device, inplace, fuse)\u001B[0m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mattempt_load_one_weight\u001B[39m(weight, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, fuse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    805\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 806\u001B[0m     ckpt, weight \u001B[38;5;241m=\u001B[39m \u001B[43mtorch_safe_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# load ckpt\u001B[39;00m\n\u001B[0;32m    807\u001B[0m     args \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mDEFAULT_CFG_DICT, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(ckpt\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_args\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))}  \u001B[38;5;66;03m# combine model and default args, preferring model args\u001B[39;00m\n\u001B[0;32m    808\u001B[0m     model \u001B[38;5;241m=\u001B[39m (ckpt\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mema\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m ckpt[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# FP32 model\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\ultralytics\\nn\\tasks.py:732\u001B[0m, in \u001B[0;36mtorch_safe_load\u001B[1;34m(weight)\u001B[0m\n\u001B[0;32m    724\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    725\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m temporary_modules(\n\u001B[0;32m    726\u001B[0m         {\n\u001B[0;32m    727\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124multralytics.yolo.utils\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124multralytics.utils\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    730\u001B[0m         }\n\u001B[0;32m    731\u001B[0m     ):  \u001B[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001B[39;00m\n\u001B[1;32m--> 732\u001B[0m         ckpt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# e.name is missing module name\u001B[39;00m\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\serialization.py:444\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 444\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\serialization.py:425\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 425\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'best_s_version.pt'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    results = model(frame)\n",
    "    \n",
    "    for r in results:\n",
    "        annotator = Annotator(frame)\n",
    "        \n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])\n",
    "    \n",
    "    frame = annotator.result()\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T18:06:04.548964Z",
     "start_time": "2024-05-27T18:05:42.650338Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 (no detections), 78.0ms\n",
      "Speed: 1.7ms preprocess, 78.0ms inference, 374.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 73.5ms\n",
      "Speed: 1.5ms preprocess, 73.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 61.0ms\n",
      "Speed: 1.2ms preprocess, 61.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 out of waters, 59.6ms\n",
      "Speed: 1.3ms preprocess, 59.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 101.1ms\n",
      "Speed: 2.0ms preprocess, 101.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 64.5ms\n",
      "Speed: 1.5ms preprocess, 64.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 68.6ms\n",
      "Speed: 1.9ms preprocess, 68.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 60.6ms\n",
      "Speed: 2.4ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 62.5ms\n",
      "Speed: 1.5ms preprocess, 62.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 out of waters, 59.4ms\n",
      "Speed: 1.5ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 63.2ms\n",
      "Speed: 1.4ms preprocess, 63.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 65.6ms\n",
      "Speed: 1.2ms preprocess, 65.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 66.7ms\n",
      "Speed: 1.6ms preprocess, 66.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 61.7ms\n",
      "Speed: 1.4ms preprocess, 61.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 67.4ms\n",
      "Speed: 1.3ms preprocess, 67.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 67.6ms\n",
      "Speed: 1.4ms preprocess, 67.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 out of water, 60.1ms\n",
      "Speed: 1.2ms preprocess, 60.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 out of water, 64.6ms\n",
      "Speed: 1.4ms preprocess, 64.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 out of water, 57.6ms\n",
      "Speed: 1.4ms preprocess, 57.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 out of water, 60.6ms\n",
      "Speed: 1.4ms preprocess, 60.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 60.7ms\n",
      "Speed: 1.3ms preprocess, 60.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 64.6ms\n",
      "Speed: 1.4ms preprocess, 64.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 64.3ms\n",
      "Speed: 1.4ms preprocess, 64.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.8ms\n",
      "Speed: 1.3ms preprocess, 60.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 64.6ms\n",
      "Speed: 1.3ms preprocess, 64.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 54.4ms\n",
      "Speed: 1.3ms preprocess, 54.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 59.7ms\n",
      "Speed: 1.2ms preprocess, 59.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 Swimming, 62.5ms\n",
      "Speed: 1.4ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.7ms\n",
      "Speed: 1.3ms preprocess, 58.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.9ms\n",
      "Speed: 1.4ms preprocess, 57.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.8ms\n",
      "Speed: 1.4ms preprocess, 57.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 Swimmings, 60.8ms\n",
      "Speed: 1.4ms preprocess, 60.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.5ms\n",
      "Speed: 1.3ms preprocess, 58.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 62.6ms\n",
      "Speed: 1.2ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 56.0ms\n",
      "Speed: 1.4ms preprocess, 56.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 61.6ms\n",
      "Speed: 1.3ms preprocess, 61.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 62.6ms\n",
      "Speed: 1.3ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.4ms\n",
      "Speed: 1.3ms preprocess, 60.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 60.6ms\n",
      "Speed: 1.3ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.8ms\n",
      "Speed: 1.3ms preprocess, 59.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.0ms\n",
      "Speed: 1.3ms preprocess, 57.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 66.0ms\n",
      "Speed: 1.3ms preprocess, 66.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.4ms\n",
      "Speed: 1.3ms preprocess, 58.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 58.8ms\n",
      "Speed: 1.3ms preprocess, 58.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 61.8ms\n",
      "Speed: 1.3ms preprocess, 61.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 58.7ms\n",
      "Speed: 1.3ms preprocess, 58.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 57.0ms\n",
      "Speed: 1.5ms preprocess, 57.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 60.5ms\n",
      "Speed: 1.2ms preprocess, 60.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.6ms\n",
      "Speed: 1.3ms preprocess, 57.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 1 out of water, 61.3ms\n",
      "Speed: 1.4ms preprocess, 61.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 59.1ms\n",
      "Speed: 1.3ms preprocess, 59.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 71.9ms\n",
      "Speed: 1.4ms preprocess, 71.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 59.2ms\n",
      "Speed: 1.2ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 53.6ms\n",
      "Speed: 1.4ms preprocess, 53.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.2ms\n",
      "Speed: 1.4ms preprocess, 59.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 57.1ms\n",
      "Speed: 1.2ms preprocess, 57.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 60.9ms\n",
      "Speed: 1.3ms preprocess, 60.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 59.2ms\n",
      "Speed: 1.4ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 65.7ms\n",
      "Speed: 1.3ms preprocess, 65.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 70.1ms\n",
      "Speed: 1.4ms preprocess, 70.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.6ms\n",
      "Speed: 1.3ms preprocess, 63.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 Swimming, 1 out of water, 62.5ms\n",
      "Speed: 1.2ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 58.3ms\n",
      "Speed: 1.4ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 61.5ms\n",
      "Speed: 1.3ms preprocess, 61.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 55.7ms\n",
      "Speed: 1.3ms preprocess, 55.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 73.9ms\n",
      "Speed: 1.5ms preprocess, 73.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 67.6ms\n",
      "Speed: 1.4ms preprocess, 67.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 56.8ms\n",
      "Speed: 1.3ms preprocess, 56.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 65.8ms\n",
      "Speed: 1.3ms preprocess, 65.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 63.2ms\n",
      "Speed: 1.3ms preprocess, 63.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 58.6ms\n",
      "Speed: 1.4ms preprocess, 58.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 59.2ms\n",
      "Speed: 1.2ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 63.4ms\n",
      "Speed: 1.5ms preprocess, 63.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 56.1ms\n",
      "Speed: 1.3ms preprocess, 56.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 56.8ms\n",
      "Speed: 1.4ms preprocess, 56.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.5ms\n",
      "Speed: 1.3ms preprocess, 59.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.3ms\n",
      "Speed: 1.3ms preprocess, 61.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 63.9ms\n",
      "Speed: 1.3ms preprocess, 63.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.5ms\n",
      "Speed: 1.3ms preprocess, 59.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.4ms\n",
      "Speed: 1.4ms preprocess, 61.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 73.4ms\n",
      "Speed: 1.3ms preprocess, 73.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 68.0ms\n",
      "Speed: 1.4ms preprocess, 68.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.8ms\n",
      "Speed: 1.3ms preprocess, 57.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.4ms\n",
      "Speed: 1.3ms preprocess, 63.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 64.0ms\n",
      "Speed: 1.4ms preprocess, 64.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.3ms\n",
      "Speed: 1.5ms preprocess, 61.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.8ms\n",
      "Speed: 1.2ms preprocess, 58.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.1ms\n",
      "Speed: 1.3ms preprocess, 61.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.6ms\n",
      "Speed: 1.3ms preprocess, 60.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.2ms\n",
      "Speed: 1.3ms preprocess, 59.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.0ms\n",
      "Speed: 1.4ms preprocess, 62.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 60.7ms\n",
      "Speed: 1.3ms preprocess, 60.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 58.1ms\n",
      "Speed: 1.2ms preprocess, 58.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 59.5ms\n",
      "Speed: 1.3ms preprocess, 59.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.2ms\n",
      "Speed: 1.3ms preprocess, 58.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 62.0ms\n",
      "Speed: 1.3ms preprocess, 62.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 60.4ms\n",
      "Speed: 1.4ms preprocess, 60.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.6ms\n",
      "Speed: 1.5ms preprocess, 58.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 61.9ms\n",
      "Speed: 1.2ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.9ms\n",
      "Speed: 1.6ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.4ms\n",
      "Speed: 1.3ms preprocess, 61.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 65.4ms\n",
      "Speed: 1.3ms preprocess, 65.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 58.3ms\n",
      "Speed: 1.3ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 63.5ms\n",
      "Speed: 1.2ms preprocess, 63.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.4ms\n",
      "Speed: 1.6ms preprocess, 60.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 60.2ms\n",
      "Speed: 1.3ms preprocess, 60.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 59.6ms\n",
      "Speed: 1.2ms preprocess, 59.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 62.6ms\n",
      "Speed: 1.3ms preprocess, 62.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 62.9ms\n",
      "Speed: 1.3ms preprocess, 62.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 1 out of water, 58.9ms\n",
      "Speed: 1.3ms preprocess, 58.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 62.6ms\n",
      "Speed: 1.2ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 63.5ms\n",
      "Speed: 1.2ms preprocess, 63.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 60.4ms\n",
      "Speed: 1.3ms preprocess, 60.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 58.5ms\n",
      "Speed: 1.3ms preprocess, 58.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 1 out of water, 57.8ms\n",
      "Speed: 1.3ms preprocess, 57.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 62.3ms\n",
      "Speed: 1.3ms preprocess, 62.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 59.6ms\n",
      "Speed: 1.4ms preprocess, 59.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 63.6ms\n",
      "Speed: 1.3ms preprocess, 63.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 66.2ms\n",
      "Speed: 1.6ms preprocess, 66.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 out of water, 61.5ms\n",
      "Speed: 1.4ms preprocess, 61.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.9ms\n",
      "Speed: 1.2ms preprocess, 60.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.2ms\n",
      "Speed: 1.6ms preprocess, 60.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 62.6ms\n",
      "Speed: 1.4ms preprocess, 62.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 1 out of water, 62.5ms\n",
      "Speed: 1.4ms preprocess, 62.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 61.4ms\n",
      "Speed: 1.3ms preprocess, 61.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 Swimming, 1 out of water, 60.1ms\n",
      "Speed: 1.4ms preprocess, 60.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 60.5ms\n",
      "Speed: 1.4ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 59.8ms\n",
      "Speed: 1.3ms preprocess, 59.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 63.8ms\n",
      "Speed: 1.3ms preprocess, 63.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.5ms\n",
      "Speed: 1.3ms preprocess, 57.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.4ms\n",
      "Speed: 1.2ms preprocess, 59.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.0ms\n",
      "Speed: 1.4ms preprocess, 60.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.0ms\n",
      "Speed: 1.6ms preprocess, 58.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 Swimmings, 55.7ms\n",
      "Speed: 1.3ms preprocess, 55.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 74.7ms\n",
      "Speed: 1.4ms preprocess, 74.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 59.0ms\n",
      "Speed: 1.4ms preprocess, 59.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.8ms\n",
      "Speed: 1.2ms preprocess, 59.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 64.3ms\n",
      "Speed: 1.5ms preprocess, 64.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.4ms\n",
      "Speed: 1.2ms preprocess, 58.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 55.2ms\n",
      "Speed: 1.4ms preprocess, 55.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.3ms\n",
      "Speed: 1.4ms preprocess, 58.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.3ms\n",
      "Speed: 1.5ms preprocess, 60.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.4ms\n",
      "Speed: 1.4ms preprocess, 62.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.9ms\n",
      "Speed: 1.3ms preprocess, 61.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.0ms\n",
      "Speed: 1.3ms preprocess, 58.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.0ms\n",
      "Speed: 1.2ms preprocess, 60.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 60.9ms\n",
      "Speed: 1.2ms preprocess, 60.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.9ms\n",
      "Speed: 1.2ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.2ms\n",
      "Speed: 1.1ms preprocess, 62.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.5ms\n",
      "Speed: 1.3ms preprocess, 60.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.4ms\n",
      "Speed: 1.4ms preprocess, 58.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 65.9ms\n",
      "Speed: 1.3ms preprocess, 65.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.2ms\n",
      "Speed: 1.6ms preprocess, 62.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 58.6ms\n",
      "Speed: 1.3ms preprocess, 58.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.4ms\n",
      "Speed: 1.2ms preprocess, 59.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.6ms\n",
      "Speed: 1.3ms preprocess, 61.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.7ms\n",
      "Speed: 1.3ms preprocess, 60.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.4ms\n",
      "Speed: 1.3ms preprocess, 62.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.2ms\n",
      "Speed: 1.4ms preprocess, 63.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 59.4ms\n",
      "Speed: 1.4ms preprocess, 59.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.8ms\n",
      "Speed: 1.3ms preprocess, 59.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.6ms\n",
      "Speed: 1.4ms preprocess, 61.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.4ms\n",
      "Speed: 1.3ms preprocess, 57.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.7ms\n",
      "Speed: 1.3ms preprocess, 61.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 62.9ms\n",
      "Speed: 1.5ms preprocess, 62.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.1ms\n",
      "Speed: 1.4ms preprocess, 59.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.0ms\n",
      "Speed: 1.2ms preprocess, 63.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.8ms\n",
      "Speed: 1.2ms preprocess, 58.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.7ms\n",
      "Speed: 1.4ms preprocess, 60.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 73.0ms\n",
      "Speed: 1.5ms preprocess, 73.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 70.7ms\n",
      "Speed: 1.2ms preprocess, 70.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 66.5ms\n",
      "Speed: 1.4ms preprocess, 66.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 66.4ms\n",
      "Speed: 1.3ms preprocess, 66.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 68.7ms\n",
      "Speed: 1.5ms preprocess, 68.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 70.7ms\n",
      "Speed: 1.2ms preprocess, 70.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.0ms\n",
      "Speed: 1.3ms preprocess, 59.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.4ms\n",
      "Speed: 1.3ms preprocess, 62.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 55.2ms\n",
      "Speed: 1.3ms preprocess, 55.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.9ms\n",
      "Speed: 1.2ms preprocess, 62.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 64.5ms\n",
      "Speed: 1.2ms preprocess, 64.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.8ms\n",
      "Speed: 1.3ms preprocess, 58.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 58.2ms\n",
      "Speed: 1.5ms preprocess, 58.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.9ms\n",
      "Speed: 1.7ms preprocess, 61.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 65.4ms\n",
      "Speed: 1.2ms preprocess, 65.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 69.2ms\n",
      "Speed: 1.3ms preprocess, 69.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 69.0ms\n",
      "Speed: 1.5ms preprocess, 69.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 60.5ms\n",
      "Speed: 1.3ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 59.5ms\n",
      "Speed: 1.3ms preprocess, 59.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 1 out of water, 57.5ms\n",
      "Speed: 1.2ms preprocess, 57.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 64.0ms\n",
      "Speed: 1.3ms preprocess, 64.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 62.2ms\n",
      "Speed: 1.3ms preprocess, 62.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.4ms\n",
      "Speed: 1.2ms preprocess, 57.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.8ms\n",
      "Speed: 1.2ms preprocess, 58.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.1ms\n",
      "Speed: 1.1ms preprocess, 61.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 68.9ms\n",
      "Speed: 1.2ms preprocess, 68.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.0ms\n",
      "Speed: 1.5ms preprocess, 61.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.9ms\n",
      "Speed: 1.3ms preprocess, 58.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.1ms\n",
      "Speed: 1.3ms preprocess, 60.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 64.1ms\n",
      "Speed: 1.2ms preprocess, 64.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.7ms\n",
      "Speed: 1.4ms preprocess, 61.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 64.7ms\n",
      "Speed: 1.2ms preprocess, 64.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.8ms\n",
      "Speed: 1.5ms preprocess, 61.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 60.9ms\n",
      "Speed: 1.4ms preprocess, 60.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 66.2ms\n",
      "Speed: 1.4ms preprocess, 66.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 60.9ms\n",
      "Speed: 1.2ms preprocess, 60.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.0ms\n",
      "Speed: 1.4ms preprocess, 57.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.0ms\n",
      "Speed: 1.2ms preprocess, 61.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 58.5ms\n",
      "Speed: 1.3ms preprocess, 58.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 57.7ms\n",
      "Speed: 1.3ms preprocess, 57.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.3ms\n",
      "Speed: 3.5ms preprocess, 60.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.3ms\n",
      "Speed: 1.3ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.2ms\n",
      "Speed: 1.2ms preprocess, 62.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.4ms\n",
      "Speed: 1.3ms preprocess, 57.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.0ms\n",
      "Speed: 1.5ms preprocess, 62.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.8ms\n",
      "Speed: 1.4ms preprocess, 62.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.6ms\n",
      "Speed: 1.5ms preprocess, 62.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.2ms\n",
      "Speed: 1.4ms preprocess, 62.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.5ms\n",
      "Speed: 1.3ms preprocess, 60.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.8ms\n",
      "Speed: 1.3ms preprocess, 61.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.5ms\n",
      "Speed: 1.3ms preprocess, 60.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 64.4ms\n",
      "Speed: 1.4ms preprocess, 64.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 64.4ms\n",
      "Speed: 1.2ms preprocess, 64.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.2ms\n",
      "Speed: 1.2ms preprocess, 59.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.1ms\n",
      "Speed: 1.3ms preprocess, 63.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 62.6ms\n",
      "Speed: 1.4ms preprocess, 62.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 64.9ms\n",
      "Speed: 1.3ms preprocess, 64.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.1ms\n",
      "Speed: 1.5ms preprocess, 60.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 57.1ms\n",
      "Speed: 1.7ms preprocess, 57.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 58.3ms\n",
      "Speed: 1.3ms preprocess, 58.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 66.9ms\n",
      "Speed: 1.2ms preprocess, 66.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.3ms\n",
      "Speed: 1.4ms preprocess, 61.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.5ms\n",
      "Speed: 1.3ms preprocess, 60.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 56.0ms\n",
      "Speed: 1.4ms preprocess, 56.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.6ms\n",
      "Speed: 1.3ms preprocess, 61.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 62.7ms\n",
      "Speed: 1.5ms preprocess, 62.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 59.4ms\n",
      "Speed: 1.3ms preprocess, 59.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.8ms\n",
      "Speed: 1.2ms preprocess, 61.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 Swimming, 61.1ms\n",
      "Speed: 1.3ms preprocess, 61.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 1 Swimming, 64.6ms\n",
      "Speed: 1.3ms preprocess, 64.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 61.3ms\n",
      "Speed: 1.4ms preprocess, 61.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.4ms\n",
      "Speed: 1.3ms preprocess, 63.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 Swimmings, 57.6ms\n",
      "Speed: 1.3ms preprocess, 57.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Swimming, 63.7ms\n",
      "Speed: 1.5ms preprocess, 63.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 60.6ms\n",
      "Speed: 1.5ms preprocess, 60.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 1 Drowning, 61.2ms\n",
      "Speed: 1.3ms preprocess, 61.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 59.0ms\n",
      "Speed: 1.2ms preprocess, 59.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.8ms\n",
      "Speed: 1.4ms preprocess, 61.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 61.9ms\n",
      "Speed: 1.4ms preprocess, 61.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 (no detections), 56.9ms\n",
      "Speed: 1.4ms preprocess, 56.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Alarm Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pydub pyaudio"
  },
  {
   "cell_type": "code",
   "source": [
    "from alarm import AlarmDetector\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T23:57:20.978162Z",
     "start_time": "2024-05-27T23:57:20.963159Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "model = YOLO(\"../models/best_s_version.pt\")\n",
    "video_path = '../video_samples/sample_01.mp4'\n",
    "alarm_sound = AudioSegment.from_file('alarm.wav')\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "calc = AlarmDetector(model, 300, 50)\n",
    "alarm = False\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    if calc.check_alarm() and not alarm:\n",
    "        alarm = True\n",
    "        play(alarm_sound)\n",
    "        play(alarm_sound)\n",
    "        # add to database and send notifications\n",
    "        \n",
    "    results = model(frame, stream=True)\n",
    "    \n",
    "    for r in results:\n",
    "        annotator = Annotator(frame)\n",
    "        \n",
    "        boxes = r.boxes\n",
    "        calc.add_boxes(boxes)\n",
    "        for box in boxes:\n",
    "            b = box.xyxy[0]\n",
    "            c = box.cls\n",
    "            annotator.box_label(b, model.names[int(c)])\n",
    "    \n",
    "    frame = annotator.result()\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T23:57:31.099721Z",
     "start_time": "2024-05-27T23:57:21.273690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 1 Swimming, 29.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 30.3ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 31.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 1 Swimming, 29.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 30.1ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.6ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.5ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 34.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 32.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 26.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 32.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 30.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.5ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 30.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 30.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 30.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.6ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.6ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 28.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 1 Swimming, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 26.5ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 29.5ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.5ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 28.3ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 32.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 29.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 Drownings, 1 Swimming, 30.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 33.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.2ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 29.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Swimming, 30.0ms\n",
      "Speed: 2.5ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.2ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 27.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.6ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 33.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 26.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.6ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 28.0ms\n",
      "Drowning\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 31.0ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Drowning, 27.5ms\n",
      "Drowning\n",
      "Speed: 1.0ms preprocess, 27.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 27.0ms\n",
      "Speed: 1.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Swimming, 28.5ms\n",
      "Speed: 1.0ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Swimming, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Swimming, 26.5ms\n",
      "Speed: 1.0ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Swimming, 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 28.0ms\n",
      "Speed: 1.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T23:47:11.855232Z",
     "start_time": "2024-05-27T23:47:11.841843Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### activate the Tracker in Yolov8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ]
}
